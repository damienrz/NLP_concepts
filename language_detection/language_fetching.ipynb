{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping language data from Wikipedia using bs4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\r\n",
    "To collect the language data needed to train various language detection\r\n",
    "models I'm going to scrape wikipedia. The lanugages I'll be focusing on \r\n",
    "are English, Japanese, Spanish, German, Russian, French, Italian, and Chinese\r\n",
    "since those 8 langauges have the most wikipedia articles. Since this is just \r\n",
    "practice I'll only be scraping one article in each langauage.\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "FOCUS = { 'en': 0, 'ja': 1, 'es': 2, 'de': 3, 'ru': 4, 'fr': 5, 'it': 6, \n",
    "          'zh': 7 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for retrieving wikipedia pages in different languages\r\n",
    "\r\n",
    "def get_hyperlinks(target_link):\r\n",
    "    r = requests.get(target_link)\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "    hyperlinks = soup.find_all(\"a\", lang=True)\r\n",
    "\r\n",
    "    lang_links = defaultdict(str)\r\n",
    "\r\n",
    "    lang_links['en'] = target_link\r\n",
    "    for h in hyperlinks:\r\n",
    "        if h['lang'] in FOCUS.keys():\r\n",
    "            lang_links[h['lang']] = h['href']\r\n",
    "    \r\n",
    "    return lang_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these regexes will be used to split each article into a list of sentences\r\n",
    "\r\n",
    "e_sents = re.compile(r'[ã€‚!?]') \r\n",
    "w_sents = re.compile(r'(?<!\\w\\.\\w\\.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s')\r\n",
    "\r\n",
    "# I also need to blacklist certain html tags to avaoid scraping unwanted data\r\n",
    "\r\n",
    "blacklist = [ '[document]', 'a', 'abbr', 'bdi', 'cite', 'div', 'h2', 'h3', \r\n",
    "              'label', 'li', 'script', 'span', 'style', 'sup', 'th', 'ul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create funciton for scraping sites/parsing sentences\r\n",
    " \r\n",
    "def fetch_lang_data(target_link):\r\n",
    "\r\n",
    "    data = []\r\n",
    "    lang_links = get_hyperlinks(target_link)\r\n",
    "\r\n",
    "    for lang, link in lang_links.items():\r\n",
    "        r = requests.get(link)\r\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "\r\n",
    "        text = soup.find_all(string=True)\r\n",
    "\r\n",
    "        output = ''\r\n",
    "        for t in text:\r\n",
    "            if t.parent.name not in blacklist:\r\n",
    "                output += '{} '.format(t)\r\n",
    "\r\n",
    "        if lang not in ['ja', 'zh']:\r\n",
    "            # fix spacing\r\n",
    "            output = re.sub(r'^\\s+', r'', output) # initial spaces\r\n",
    "            output = re.sub(r'\\(\\s+\\)', r' ', output) # empty parenthesis\r\n",
    "            output = re.sub(r\"\\s+([,.'\\\":])\", r'\\1', output) # spaced punctuation\r\n",
    "            output = re.sub(r'(\\s{2,})', r' ', output) # long spaces\r\n",
    "            # parse sentences\r\n",
    "            output = w_sents.split(output)\r\n",
    "        else:\r\n",
    "            # fix spacing\r\n",
    "            output = re.sub(r'^\\s+', r'', output) # initial spaces\r\n",
    "            output = re.sub(r'\\s{2,}', r' ', output) # long spaces\r\n",
    "            # parse sentences\r\n",
    "            output = e_sents.split(output)\r\n",
    "        \r\n",
    "        for sent in output:\r\n",
    "            data.append((lang, sent))\r\n",
    "\r\n",
    "    return data\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Alice's Adventures in Wonderland - Wikipedia A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>It tells of a young girl named, who falls thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>It is considered to be one of the best example...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>The tale plays with, giving the story lasting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>One of the best-known and most popular works o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           sentence\n",
       "0       en  Alice's Adventures in Wonderland - Wikipedia A...\n",
       "1       en  It tells of a young girl named, who falls thro...\n",
       "2       en  It is considered to be one of the best example...\n",
       "3       en  The tale plays with, giving the story lasting ...\n",
       "4       en  One of the best-known and most popular works o..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get language data as a list of tuples\r\n",
    "\r\n",
    "language_data = fetch_lang_data(\"https://en.wikipedia.org/wiki/Alice's_Adventures_in_Wonderland\")\r\n",
    "\r\n",
    "# create dataframe from laguage data\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "language_df = pd.DataFrame(language_data, columns=['language', 'sentence'])\r\n",
    "language_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\r\n",
    "\r\n",
    "spacy_packs = { 'en': 'en_core_web_md', \r\n",
    "                'ja': 'ja_core_news_md', \r\n",
    "                'es': 'es_core_news_md', \r\n",
    "                'de': 'de_core_news_md', \r\n",
    "                'ru': 'ru_core_news_md', \r\n",
    "                'fr': 'fr_core_news_md', \r\n",
    "                'it': 'it_core_news_md', \r\n",
    "                'zh': 'zh_core_web_md' }\r\n",
    "\r\n",
    "# create function that tokenizes each sentence in the dataframe, lemmatizes them, \r\n",
    "# and removes stopwords, punctuation, and numbers\r\n",
    "\r\n",
    "def tokenize(sentence, lang):\r\n",
    "    doc = nlp(sentence)\r\n",
    "    if lang == 'zh':\r\n",
    "        return [tok.text for tok in doc if not tok.is_punct and tok.pos_ != 'NUM']\r\n",
    "    else:\r\n",
    "        return [tok.lemma_.lower() for tok in doc if not tok.is_punct \r\n",
    "            and not tok.is_stop and not tok.is_space and tok.pos_ != 'NUM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe code below would create one-hot vectors for each target language,\\nbut since I'll be using the CrossEntropyLoss function later I have to encode\\nthe target languages as integers instead\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode language (integer encoding)\r\n",
    "language_df['language_code'] = language_df['language'].apply(lambda x: FOCUS[x])\r\n",
    "\r\n",
    "'''\r\n",
    "The code below would create one-hot vectors for each target language,\r\n",
    "but since I'll be using the CrossEntropyLoss function later I have to encode\r\n",
    "the target languages as integers instead\r\n",
    "'''\r\n",
    "# import numpy as np\r\n",
    "# language_df['one_hot_vector'] = language_df['language'].apply(lambda x: np.eye(8)[LABELS[x]].astype('int').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe by each language, apply tokenizing function to it, \r\n",
    "# and add to list\r\n",
    "\r\n",
    "series_list = []\r\n",
    "for lang, pack in spacy_packs.items():\r\n",
    "    nlp = spacy.load(pack, disable=['ner', 'parser'])\r\n",
    "    series = language_df[language_df['language']==lang]['sentence'].apply(tokenize, args=(lang,))\r\n",
    "    series_list.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>language_code</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Alice's Adventures in Wonderland - Wikipedia A...</td>\n",
       "      <td>0</td>\n",
       "      <td>[alice, adventures, wonderland, wikipedia, ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>It tells of a young girl named, who falls thro...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tell, young, girl, name, fall, rabbit, hole, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>It is considered to be one of the best example...</td>\n",
       "      <td>0</td>\n",
       "      <td>[consider, good, example, genre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>The tale plays with, giving the story lasting ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tale, play, give, story, last, popularity, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>One of the best-known and most popular works o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[well, know, popular, work, english, language,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           sentence  language_code  \\\n",
       "0       en  Alice's Adventures in Wonderland - Wikipedia A...              0   \n",
       "1       en  It tells of a young girl named, who falls thro...              0   \n",
       "2       en  It is considered to be one of the best example...              0   \n",
       "3       en  The tale plays with, giving the story lasting ...              0   \n",
       "4       en  One of the best-known and most popular works o...              0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [alice, adventures, wonderland, wikipedia, ali...  \n",
       "1  [tell, young, girl, name, fall, rabbit, hole, ...  \n",
       "2                   [consider, good, example, genre]  \n",
       "3  [tale, play, give, story, last, popularity, ad...  \n",
       "4  [well, know, popular, work, english, language,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat list of series\r\n",
    "\r\n",
    "tokens = pd.concat(series_list)\r\n",
    "\r\n",
    "# add tokens column to dataframe and output as pickle\r\n",
    "\r\n",
    "language_df = language_df.assign(tokens=tokens)\r\n",
    "# remove rows with empty tokens list\r\n",
    "language_df = language_df[~language_df['tokens'].apply(lambda x: len(x)==0)]\r\n",
    "language_df.to_pickle('language_data.pickle')\r\n",
    "\r\n",
    "language_df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6bdf263dd1b1cef4309b77b00a11a6b470a762f164881b61a60ce80391d462c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('nlp_venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}