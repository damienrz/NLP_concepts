{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Scraping language data from Wikipedia using bs4 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To collect the language data needed to train various language detection models I'm going to scrape articles from Wikipedia. The languages I'll be focusing on are English, Japanese, Spanish, German, Russian, French, Italian, and Chinese since most Wikipedia articles are written in those 8 langauges. Since this is just practice I'll only be scraping one article (written in each langauage)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re, requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from collections import defaultdict\r\n",
    "# I'll use this dictionary for integer encoding later\r\n",
    "FOCUS = { 'en': 0, 'ja': 1, 'es': 2, 'de': 3, 'ru': 4, 'fr': 5, 'it': 6, \r\n",
    "          'zh': 7 }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# create function for retrieving the link for a wikipedia article in different languages\r\n",
    "\r\n",
    "def get_hyperlinks(target_link):\r\n",
    "    r = requests.get(target_link)\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "    hyperlinks = soup.find_all(\"a\", lang=True)\r\n",
    "\r\n",
    "    lang_links = defaultdict(str)\r\n",
    "\r\n",
    "    lang_links['en'] = target_link\r\n",
    "    for h in hyperlinks:\r\n",
    "        if h['lang'] in FOCUS.keys():\r\n",
    "            lang_links[h['lang']] = h['href']\r\n",
    "    \r\n",
    "    # return defaultdict\r\n",
    "    return lang_links"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# these regexes will be used to split each article into a list of sentences\r\n",
    "# I prefer using my own custorm regex for this task step in processing\r\n",
    "\r\n",
    "e_sents = re.compile(r'[！!？?。]') # eastern languages\r\n",
    "w_sents = re.compile(r'(?<!\\w\\.\\w\\.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s') # western languages\r\n",
    "\r\n",
    "# I also need to blacklist certain html tags to avoid scraping unwanted data\r\n",
    "\r\n",
    "blacklist = [ '[document]', 'a', 'abbr', 'bdi', 'cite', 'div', 'h2', 'h3', \r\n",
    "              'label', 'li', 'script', 'span', 'style', 'sup', 'th', 'ul']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    " # create funciton for scraping articles / parsing sentences\r\n",
    " \r\n",
    "def fetch_lang_data(target_link):\r\n",
    "\r\n",
    "    data = []\r\n",
    "    lang_links = get_hyperlinks(target_link)\r\n",
    "\r\n",
    "    for lang, link in lang_links.items():\r\n",
    "        r = requests.get(link)\r\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "\r\n",
    "        text = soup.find_all(string=True)\r\n",
    "\r\n",
    "        output = ''\r\n",
    "        for t in text:\r\n",
    "            if t.parent.name not in blacklist:\r\n",
    "                output += '{} '.format(t)\r\n",
    "\r\n",
    "        if lang not in ['ja', 'zh']:\r\n",
    "            # fix spacing\r\n",
    "            output = output.strip()\r\n",
    "            output = re.sub(r'\\(\\s+\\)', r' ', output) # empty parenthesis\r\n",
    "            output = re.sub(r\"\\s+([,.'\\\":])\", r'\\1', output) # spaced punctuation\r\n",
    "            output = re.sub(r'(\\s{2,})', r' ', output) # long spaces\r\n",
    "            # parse sentences\r\n",
    "            output = w_sents.split(output)\r\n",
    "        else:\r\n",
    "            # fix spacing\r\n",
    "            output = output.strip()\r\n",
    "            output = re.sub(r'\\s{2,}', r' ', output) # long spaces\r\n",
    "            # parse sentences\r\n",
    "            output = e_sents.split(output)\r\n",
    "        \r\n",
    "        for sent in output:\r\n",
    "            data.append((lang, sent))\r\n",
    "\r\n",
    "    # return list of tuples\r\n",
    "    return data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# get language data as a list of tuples\r\n",
    "\r\n",
    "article_link = \"https://en.wikipedia.org/wiki/Alice's_Adventures_in_Wonderland\"\r\n",
    "language_data = fetch_lang_data(article_link)\r\n",
    "\r\n",
    "# create dataframe from language data\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "language_df = pd.DataFrame(language_data, columns=['language', 'sentence'])\r\n",
    "\r\n",
    "# create column with language encodings (integer encoding)\r\n",
    "language_df['language_code'] = language_df['language'].apply(lambda x: FOCUS[x])\r\n",
    "\r\n",
    "# import numpy as np\r\n",
    "\r\n",
    "## create column with one-hot encodings\r\n",
    "# language_df['one_hot_vector'] = language_df['language'].apply(lambda x: np.eye(8)[LABELS[x]].astype('int').tolist())\r\n",
    "\r\n",
    "language_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  language                                           sentence  language_code\n",
       "0       en  Alice's Adventures in Wonderland - Wikipedia A...              0\n",
       "1       en  A young girl named falls through a rabbit hole...              0\n",
       "2       en        It is seen as a prime example of the genre.              0\n",
       "3       en  Its play with gives the story lasting populari...              0\n",
       "4       en  One of the best-known works of Victorian Engli...              0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>language_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Alice's Adventures in Wonderland - Wikipedia A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>A young girl named falls through a rabbit hole...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>It is seen as a prime example of the genre.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>Its play with gives the story lasting populari...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>One of the best-known works of Victorian Engli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import spacy\r\n",
    "\r\n",
    "spacy_models = { 'en': 'en_core_web_md', \r\n",
    "                'ja': 'ja_core_news_md', \r\n",
    "                'es': 'es_core_news_md', \r\n",
    "                'de': 'de_core_news_md', \r\n",
    "                'ru': 'ru_core_news_md', \r\n",
    "                'fr': 'fr_core_news_md', \r\n",
    "                'it': 'it_core_news_md', \r\n",
    "                'zh': 'zh_core_web_md' }\r\n",
    "\r\n",
    "# create function that tokenizes each sentence in the dataframe, lemmatizes them, \r\n",
    "# and removes stopwords, punctuation, and numbers\r\n",
    "\r\n",
    "def tokenize(sentence, lang):\r\n",
    "    doc = nlp(sentence)\r\n",
    "    if lang == 'zh':\r\n",
    "        return [tok.text for tok in doc if not tok.is_punct and tok.pos_ != 'NUM']\r\n",
    "    else:\r\n",
    "        return [tok.lemma_.lower() for tok in doc if not tok.is_punct \r\n",
    "            and not tok.is_stop and not tok.is_space and tok.pos_ != 'NUM']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# filter dataframe by each language, apply tokenizing function to it, and add to list\r\n",
    "\r\n",
    "series_list = []\r\n",
    "\r\n",
    "for lang, model in spacy_models.items():\r\n",
    "    nlp = spacy.load(model, disable=['ner', 'parser'])\r\n",
    "    series = language_df[language_df['language']==lang]['sentence'].apply(tokenize, args=(lang,))\r\n",
    "    series_list.append(series)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# concat the list of series\r\n",
    "tokens = pd.concat(series_list)\r\n",
    "\r\n",
    "# add tokens column to dataframe\r\n",
    "language_df = language_df.assign(tokens=tokens)\r\n",
    "# remove rows with empty tokens list\r\n",
    "language_df = language_df[~language_df['tokens'].apply(lambda x: len(x)==0)]\r\n",
    "# output as pickle\r\n",
    "language_df.to_pickle('language_data.pickle')\r\n",
    "\r\n",
    "language_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  language                                           sentence  language_code  \\\n",
       "0       en  Alice's Adventures in Wonderland - Wikipedia A...              0   \n",
       "1       en  A young girl named falls through a rabbit hole...              0   \n",
       "2       en        It is seen as a prime example of the genre.              0   \n",
       "3       en  Its play with gives the story lasting populari...              0   \n",
       "4       en  One of the best-known works of Victorian Engli...              0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [alice, adventures, wonderland, wikipedia, ali...  \n",
       "1  [young, girl, name, fall, rabbit, hole, fantas...  \n",
       "2                       [see, prime, example, genre]  \n",
       "3  [play, give, story, last, popularity, adult, c...  \n",
       "4  [well, know, work, victorian, english, fiction...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>language_code</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Alice's Adventures in Wonderland - Wikipedia A...</td>\n",
       "      <td>0</td>\n",
       "      <td>[alice, adventures, wonderland, wikipedia, ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>A young girl named falls through a rabbit hole...</td>\n",
       "      <td>0</td>\n",
       "      <td>[young, girl, name, fall, rabbit, hole, fantas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>It is seen as a prime example of the genre.</td>\n",
       "      <td>0</td>\n",
       "      <td>[see, prime, example, genre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>Its play with gives the story lasting populari...</td>\n",
       "      <td>0</td>\n",
       "      <td>[play, give, story, last, popularity, adult, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>One of the best-known works of Victorian Engli...</td>\n",
       "      <td>0</td>\n",
       "      <td>[well, know, work, victorian, english, fiction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6bdf263dd1b1cef4309b77b00a11a6b470a762f164881b61a60ce80391d462c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('nlp_venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}